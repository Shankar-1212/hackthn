{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVt_ILxd9nhw",
    "outputId": "04ffa8a4-8729-4ab5-ceb4-a10c649c2810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHZAg7vu9oWF",
    "outputId": "78073c28-ced7-4897-85ee-25f2550f24cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped /content/drive/MyDrive/png-images.zip to /content/drive/MyDrive/\n",
      "Unzipped /content/drive/MyDrive/new-20241016T105852Z-001.zip to /content/drive/MyDrive/\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Paths to the zip files and where you want to unzip them\n",
    "png_images = '/content/drive/MyDrive/png-images.zip'  # Update with the path to your first zip file\n",
    "healthy = '/content/drive/MyDrive/new-20241016T105852Z-001.zip'  # Update with the path to your second zip file\n",
    "\n",
    "output_dir_1 = '/content/drive/MyDrive/'  # Folder where you want to unzip the first file\n",
    "output_dir_2 = '/content/drive/MyDrive/'  # Folder where you want to unzip the second file\n",
    "\n",
    "# Function to unzip a file\n",
    "def unzip_file(zip_file, output_dir):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "    print(f'Unzipped {zip_file} to {output_dir}')\n",
    "\n",
    "# Unzipping the first folder\n",
    "unzip_file(png_images, output_dir_1)\n",
    "\n",
    "# Unzipping the second folder\n",
    "unzip_file(healthy, output_dir_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5ar9emc9opn",
    "outputId": "57fa2f5b-6ee5-45b6-8519-b6eef489c48a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets combined successfully into: /content/drive/MyDrive/combined-lesion\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths to the original lesion and synthetic lesion directories\n",
    "original_lesion_dir = '/content/drive/MyDrive/png-images'\n",
    "synthetic_lesion_dir = '/content/drive/MyDrive/1729016248.5377333'\n",
    "combined_lesion_dir = '/content/drive/MyDrive/combined-lesion'\n",
    "\n",
    "# Create the combined lesion directory if it doesn't exist\n",
    "if not os.path.exists(combined_lesion_dir):\n",
    "    os.makedirs(combined_lesion_dir)\n",
    "\n",
    "# Copy original lesion images to the combined folder\n",
    "for filename in os.listdir(original_lesion_dir):\n",
    "    file_path = os.path.join(original_lesion_dir, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        shutil.copy(file_path, combined_lesion_dir)\n",
    "\n",
    "# Copy synthetic lesion images to the combined folder\n",
    "for filename in os.listdir(synthetic_lesion_dir):\n",
    "    file_path = os.path.join(synthetic_lesion_dir, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        shutil.copy(file_path, combined_lesion_dir)\n",
    "\n",
    "print(\"Datasets combined successfully into:\", combined_lesion_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKK8TtOU9ovF",
    "outputId": "117b152a-0eb5-44e7-cdfb-46f87b585fe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1208 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 4s/step - accuracy: 0.7076 - loss: 0.5428 - val_accuracy: 0.8368 - val_loss: 0.4331\n",
      "Epoch 2/10\n",
      "\u001b[1m 1/75\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8750 - loss: 0.3100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.8750 - loss: 0.3100 - val_accuracy: 0.8571 - val_loss: 0.3939\n",
      "Epoch 3/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 4s/step - accuracy: 0.9032 - loss: 0.3025 - val_accuracy: 0.9549 - val_loss: 0.1680\n",
      "Epoch 4/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0744 - val_accuracy: 0.9286 - val_loss: 0.1031\n",
      "Epoch 5/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 4s/step - accuracy: 0.9455 - loss: 0.1575 - val_accuracy: 0.9549 - val_loss: 0.1135\n",
      "Epoch 6/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0733 - val_accuracy: 0.9286 - val_loss: 0.0866\n",
      "Epoch 7/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 4s/step - accuracy: 0.9696 - loss: 0.1117 - val_accuracy: 0.9826 - val_loss: 0.0366\n",
      "Epoch 8/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0824 - val_accuracy: 1.0000 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 4s/step - accuracy: 0.9824 - loss: 0.0592 - val_accuracy: 0.9826 - val_loss: 0.0405\n",
      "Epoch 10/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 573ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 5s/step - accuracy: 0.9886 - loss: 0.0304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 98.34%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up paths for your data\n",
    "combined_lesion_dir = '/content/drive/MyDrive/combined-lesion'  # Path for combined synthetic and original lesion images\n",
    "healthy_dir = '/content/drive/MyDrive/new'  # Path for healthy images\n",
    "\n",
    "# Check if directories exist\n",
    "assert os.path.exists(combined_lesion_dir), \"Combined lesion data directory does not exist!\"\n",
    "assert os.path.exists(healthy_dir), \"Healthy data directory does not exist!\"\n",
    "\n",
    "# Data augmentation settings\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # 20% validation split\n",
    ")\n",
    "\n",
    "# Training and validation data generators\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory='/content/drive/MyDrive',\n",
    "    classes=['combined-lesion', 'new'],\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory='/content/drive/MyDrive',\n",
    "    classes=['combined-lesion', 'new'],\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,  # Adjust the number of epochs as needed\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the final trained model\n",
    "model.save('/content/drive/MyDrive/final_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QfUNv_k9o4i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2QU8jbP9o-K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_eZS9tFL9pC4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEAoZHI49pHS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtRiyNdB9pLt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtFKQazX9pP2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
